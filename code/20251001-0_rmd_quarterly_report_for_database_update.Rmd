---
title: "NOAA National Database for Deep-sea Corals and Sponges: Quarterly Data Update Announcement"
author: "NOAA-NFMS-OHC-DSCRTP"
date: 'Contact: Robert.McGuinn@NOAA.gov; Report last ran: `r Sys.Date()`'

output: 
  word_document

editor_options: 
  chunk_output_type: console

params:
  quarter: "Q4, FY-2025"
  version: "DSCRTP_NatDB_20251001-0"
  releasedate: "2025-10-15"
  corrections: 383158
  filename: 'default'
  last_db: 'DSCRTP_NatDB_20250714-0.csv'
  this_db: 'DSCRTP_NatDB_20251001-0.csv'
  newdatasetIDs: !r c("OET_NA168","OET_NA156")
---


```{r packages, echo=F, warning=F, message=F}
library(openxlsx)
library(sp)
library(tidyverse)
library(leaflet)
library(extrafont)
# font_import()
library(RColorBrewer)
library(googledrive)
library(rmarkdown)
library(knitr)
library(maps)
library(raster)
library(prettydoc)

```

```{r manual_load_both_db, echo=FALSE, cache=F, eval=F}
##### [Manual] bring last two databases (old one first)
setwd("C:/rworking/deepseatools/indata")
indata1<- read.csv(params$last_db, 
                  header = T, 
                  encoding = 'latin1')
filt1 <- indata1 %>%
  filter(Flag == "0")

rm(indata1)
##### bring new db in #####
setwd("C:/rworking/deepseatools/indata")
indata2<-read.csv(params$this_db, 
                  header = T, 
                  encoding = 'latin1')
filt <- indata2 %>%
  filter(Flag == "0")
rm(indata2)

```

```{r manual_load, echo=FALSE, cache=F}
# find the maximum new CatalogNumber
z <- max(as.numeric(filt$CatalogNumber))
# y <- max(as.numeric(filt2$CatalogNumber))

## calc number new datasets added this round 
a <- length(params$newdatasetIDs)

##### make a subset of just those new CatalogNumber(s)
x <- filt %>% 
  filter(DatasetID %in% params$newdatasetIDs)

##### make all -999 values in InvidualCount = 1.  This is a simplifying measure 
## for ease of counting individual observations. This mutatded 'IndividualCount' should not be used for analysis.
x <- x %>%  mutate(IndividualCount = ifelse(IndividualCount == -999,
                                           yes = 1,
                                           no = IndividualCount))


new_records <- length(x$CatalogNumber)

```

```{r load_functions, warning = FALSE, message=FALSE, echo=FALSE}
##### Define Key Functions #####
Trim <- function(x){
    gsub("^\\s+|\\s+$", "", x)
}
TrimAll <- function(x){
    dat<-Trim(x[,c(x)])
    x[,c(x)] <- dat
}

```

# Quarterly update for: `r params$quarter`
## Database Version: `r params$version`

The Deep Sea Coral Research and Technology Program is proud to announce that the latest quarterly update of the National Database for Deep Sea Corals and Sponges is available. **`r prettyNum(a, big.mark = ',')`** new datasets were either added or augmented with a total of **`r prettyNum(new_records, big.mark = ',')`** updated and improved records. There is now a grand total of **`r prettyNum(length(filt$CatalogNumber), big.mark = ',')`** records in the database. We have also made corrections and improvements to **`r prettyNum(as.numeric(params$corrections), big.mark = ',')`** records. We would love to have your feedback for future data improvements. 

Go here to view and download custom data subsets of your choosing:
https://www.ncei.noaa.gov/maps/deep-sea-corals-portal/

*A big thank you to all of our data providers! This database is a key resource for data-driven deep sea coral and sponge habitat conservation and management. We welcome your questions and feedback.*

Please see the following tables and figures for additional detail regarding this update.  

# This Update by the Numbers

* Total number of records now in database: **`r  prettyNum(length(filt$CatalogNumber), big.mark=",")`**

* Number of new database records added this quarter: **`r  prettyNum(length(x$CatalogNumber), big.mark=",")`**

* Individual coral and sponge observations added: **`r prettyNum(sum(x$IndividualCount[x$IndividualCount != "-999"]), big.mark = ',')`**

* Number of EventID(s) (number of dives/trawls/transects): **`r prettyNum(length(unique(x$EventID)), ',')`**

* Observation Time Frame: **`r min(as.numeric(x$ObservationYear[x$ObservationYear != "-999"]), na.rm=TRUE)` to `r max(x$ObservationYear, na.rm=TRUE)`**

* Latest database version name: **`r as.character(params$version)`**

* Date live on map portal: **`r paste("posted on", params$releasedate, sep = " ")`**

# Overview map

```{r, map, echo = FALSE, message = FALSE, warning=FALSE, fig.width=8, fig.height=5, dpi=300, cache=FALSE}

# ##### Using ggmap libary #####
#getting rid of  missing lat/long data
# x2 <- x %>%
#   filter(Latitude != '-999' |
#            Longitude != '-999',
#          AccessionID != 'Pante_et_al_2015')

# # use this when not crossing dateline
# xpos <- x2$Longitude
# # also use this additional calculation to transforming longitudes to 0-360 if crossing dateline as in Western AK and HI
# xpos <- ifelse(xpos < 0, (180-xpos*(-1))+180, xpos)
# 
# #myLocation <- c(lon = mean(xpos), lat = mean(x2$Latitude))
# #manually set center longitude if in an area that crosses dateline
# myLocation <- c(lon = 180, lat = mean(x2$Latitude))
# 
# p <- get_map(location=myLocation, source='google', maptype='satellite', crop=FALSE, zoom=2)
# # put transLong below if 
# ggmap(p)+
#   geom_point(aes(x = xpos, y = Latitude), data = x2,
#              alpha = .5, color="darkred", size = 2)+ 
#   theme_bw(base_size = 15, base_family = "Cambria") + 
#   labs(x = "Longitude", y = "Latitude")
# 
#  xpos <- x3$Longitude
# # # also use this additional calculation to transforming longitudes to 0-360 if crossing dateline as in Western AK and HI
# # xpos <- ifelse(xpos < 0, (180-xpos*(-1))+180, xpos)
# #
#  myLocation <- c(lon = mean(xpos), lat = mean(x3$Latitude))
#  #manually set center longitude if in an area that crosses dateline
#  #myLocation <- c(lon = 174.886, lat = mean(sub2$Latitude))
# 
#  p <- get_map(location=myLocation, source='google', maptype='satellite', crop=FALSE, zoom=3)
#  ggmap(p) +
#    geom_point(aes(x = xpos, y = Latitude), data = x3,
#               alpha = .5, color="darkred", size = 2) +
#    theme_bw(base_size = 15, base_family = "Cambria") +
#    labs(x = "Longitude", y = "Latitude")
# 
# #getting rid of  missing lat/long data
# caribb <- x %>%
#   filter(grepl('Caribbean', AccessionID))
# 
# # use this when not crossing dateline
# xpos <- caribb$Longitude
# # also use this additional calculation to transforming longitudes to 0-360 if crossing dateline as in Western AK and HI
# #xpos <- ifelse(xpos < 0, (180-xpos*(-1))+180, xpos)
# 
# myLocation <- c(lon = mean(xpos), lat = mean(caribb$Latitude))
# #manually set center longitude if in an area that crosses dateline
# #myLocation <- c(lon = 180, lat = mean(caribb$Latitude))
# 
# p <- get_map(location=myLocation, source='google', maptype='satellite', crop=FALSE, zoom=9)
# # put transLong below if 
# ggmap(p)+
#   geom_point(aes(x = xpos, y = Latitude), data = caribb,
#              alpha = .5, color="darkred", size = 2)+ 
#   theme_bw(base_size = 15, base_family = "Cambria") + 
#   labs(x = "Longitude", y = "Latitude")

library(dplyr)
library(ggplot2)

m <- map_data("world")  

z <- ggplot(m, aes(x = long, y = lat, group = group)) +
  geom_polygon()

z + geom_point(data=x, 
               color = "red", 
               size = 1, 
               aes(x=Longitude, y = Latitude), inherit.aes = FALSE) + 
  scale_color_manual(values=c("#999999", "#E69F00")) + theme_bw(base_size = 15, base_family = "Times New Roman")
```

-----

# Where?

``` {r Ocean, echo=FALSE}
x <- x %>% mutate(Country = ifelse(is.na(Country) == T, 'International Waters', as.character(Country)))

sum_tbl <-
  x %>%
  #filter(Phylum == "Porifera") %>%
  group_by(FishCouncilRegion) %>%
  summarize(Ocean = toString(unique(Ocean)), 
            #FishCouncilRegion = toString(unique(FishCouncilRegion)),
            Country = toString(unique(Country)),
            n = n()) %>%
  arrange(desc(n))
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2, format.args = list(big.mark = ","))
sum_tbl

```

-----

# Corals vs. Sponges vs. Fishes

```{r corals_sponges, echo=FALSE, cache = FALSE, dpi=300, fig.height=3, fig.width=8}
#library(extrafont)
#loadfonts(device = "win")

x$Phylum <- factor(x$Phylum, levels=c('Cnidaria','Porifera','Chordata'))

g <- ggplot(x, aes(Phylum, fill = Phylum)) +
  geom_bar() + 
 # coord_flip() + 
  theme(text = element_text(size=20)) + 
  ylab("Number of Records") + 
  theme_bw(base_size = 15)

#display.brewer.all(colorblindFriendly=TRUE)
g + scale_fill_manual(values = brewer.pal(12, "Paired")[c(8,7,6)])

```

-----

# Distribution of Taxa by Order

```{r orders, echo=FALSE, cache = FALSE, dpi=300, fig.height=6, fig.width=8, message=FALSE, warning=FALSE}
##### building big pallette #####
# to get the colors from a palette:
palette1 <- brewer.pal(9,"Set1")
palette2 <- brewer.pal(8,"Set2")
palette3 <- brewer.pal(9,"Set3")
palette4 <- brewer.pal(8,"Dark2")
palette5 <- brewer.pal(8,"Accent")

# We can just stick a few color palettes together
big_palette <- c(palette1,palette2,palette3, palette4, palette5)

x <- within(x, 
             Order <- factor(Order, 
                                  levels=names(sort(table(Order), decreasing=TRUE))))

##### graphing the orders #####
g <- ggplot(x, aes(Order)) +
  geom_bar() + 
 # coord_flip() + 
  #theme(text = element_text(size=10)) + 
  ylab("Number of Records") + 
  facet_wrap(~Phylum, scales="free") +
  theme_bw(base_size = 15, base_family = "Cambria")

set.seed(7)
g + scale_fill_manual(values = sample(big_palette)) + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.05, size = 7))

```

-----

# Who Contributed to this Update?

``` {r DataProvider, echo=FALSE}

# # Data Provider corrections
# x$DataProvider <- 
#   plyr::revalue(x$DataProvider,
#                 c('Kelley, Christopher (CKelley@hawaii.edu)' = 'NOAA, Deep Sea Coral Research & Technology Program and Office of Ocean Exploration and Research'))
# 
# x$DataContact <- 
#   plyr::revalue(x$DataContact, 
#                 c('2017-12-18' =  'Kelley, Chris: ckelley@hawaii.edu','Pante, Eric (eric.pante@univ-lr.fr)' = 'Pante, Eric: eric.pante@univ-lr.fr', "Battista, Tim; Tim.Battista@noaa.gov" = "Battista, Tim: Tim.Battista@noaa.gov", "Thoma, Jana" = "Thoma, Jana: jana.thoma@louisiana.edu"))
                  
# table(factor(x$DataProvider))
# table(factor(x$PI))
# table(factor(x$DataContact))
x$url <- paste0('https://www.ncei.noaa.gov/waf/dsc-data/dashboards/',
                      x$DatasetID, 
                      '.html', 
                      sep = '')

x$DashBoard <- paste0("[", x$DatasetID, "](", x$url, ")")

sum_tbl <-
  x %>%
  group_by(DataProvider) %>%
  summarize(DatasetID = toString(unique(DashBoard)), 
            PI = toString(unique(unlist(unique(strsplit(as.character(PI), '; '))))),
            DataContact = toString(unique(DataContact)),
            Reporter = toString(unique(Reporter)),
            n = n()) %>%
  arrange(desc(DatasetID))
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2, format.args = list(big.mark = ","))
sum_tbl
```

-----

# Expedition Details

``` {r Vessel, echo=FALSE}



sum_tbl <-
  x %>%
  group_by(DatasetID) %>%
  summarize(Vessel = toString(unique(Vessel)),
            #SurveyID = toString(unique(SurveyID)),
            SamplingEquipment = toString(unique(SamplingEquipment)),
            RecordType = toString(unique(RecordType)),
            #BeginYear= min(as.numeric(ObservationYear)),
            EndYear= max(as.numeric(ObservationYear)),
            n = prettyNum(n(),big.mark = ',')) %>% 
  arrange(desc(DatasetID))

sum_tbl$url <- paste0('https://www.ncei.noaa.gov/waf/dsc-data/dashboards/',
                      sum_tbl$DatasetID, 
                      '.html', 
                      sep = '')

sum_tbl$DashBoard <- paste0("[", "Dashboard Link", "](", sum_tbl$url, ")")
sum_tbl <- sum_tbl %>% dplyr::select(-url)
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2)
sum_tbl
```

-----

