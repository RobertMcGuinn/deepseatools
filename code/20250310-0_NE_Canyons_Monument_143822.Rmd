---
title: "Area of Interest Report - Northeast Canyons and Seamounts National Monument"
author: "Robert P. McGuinn"
date: "April 2, 2025"
output: word_document
---

```{r packages, eval=T, echo=F, message=FALSE, warning=FALSE, cache=FALSE}
## load packages
#install.packages(tidyverse)
#install.packages('openxlsx')
library(tidyverse)
library(openxlsx)
library(sf)
library(RColorBrewer)
library(raster)
library(leaflet)
library(extrafont)
library(RColorBrewer)
library(rmarkdown)
library(knitr)
library(maps)
library(raster)
library(httr)
library(jsonlite)
library(rnaturalearth)
library(rnaturalearthdata)
library(openxlsx)
library(googledrive)
library(spocc)
library(terra)

```

```{r load_NDB, echo=F, message = FALSE, warning = FALSE, cache = TRUE, eval = F}
## load NDB
source('c:/rworking/deepseatools/code/mod_load_current_NDB.R')

```

```{r set_ndb_version, echo=F, eval=T}
## create needed variables
db_version <- unique(filt$DatabaseVersion)

```

```{r filter_geo_OR_query, echo=F, warning=F, message=F, eval=T}
##### filter occurrences by query or box or both ##### 

## set bounding box variables
minlat <- 37
maxlat <- 43
minlon <- -72
maxlon <- -61

## subset data by coordinates
x <- subset(filt, as.numeric(Latitude) > minlat &
                   as.numeric(Latitude) < maxlat &
                   as.numeric(Longitude) > minlon &
                   as.numeric(Longitude) < maxlon)
                
## also subset data by other variables by other criteria
# x <- x %>% filter(ScientificName == "")

## checking
# dim(x)

```

```{r create_geo_from_points, echo=FALSE, echo = FALSE, message = FALSE, warning=FALSE, eval=T}
## create spatial points data frame from a subset of points
x_geo <- x

## create spdf
coordinates(x_geo) <- c("Longitude", "Latitude")
proj4string(x_geo) <- "+proj=longlat +ellps=WGS84 +datum=WGS84"

## OPTIONAL: write out featureclass to geodatabase from sp object 
# fgdb_path <- "C:/data/aprx/aoi/aoi.gdb"
# arc.write(file.path(fgdb_path, 'x_geo'), data=x_geo, overwrite = TRUE)

```

```{r create_sf_from_points, message = FALSE, warning = FALSE, echo=T}
## transform coral and sponge occurrence points to 'sf' objects
##### transform coral and sponge points to sf #####
points <- st_as_sf(x_geo, wkt = "geom")

## OPTIONAL: write out featureclass from sf object
# fgdb_path <- "C:/data/aprx/aoi/aoi.gdb"
# arc.write(file.path(fgdb_path, 'points'), data=points, overwrite = TRUE)
rm(x)

```

```{r import_NE_Canyons_aoi, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=T, }

##### get the NE Canyons mounument ##### 
shapefile_path <- "C:/rworking/deepseatools/indata/20221104_protected_areas_update_HColeman/20221104_protected_areas.shp"
protected_areas <- st_read(shapefile_path)
ne_canyons <- protected_areas %>% filter(Sitename == 'NE Canyons and Seamounts')

##### reproject to target crs ##### 
ne_canyons_5070 <- st_transform(ne_canyons, crs = 5070)

##### Convert sf to SpatVector ##### 
ne_canyons_5070_spat <- vect(ne_canyons_5070)

##### Write to shapefile #####
writeVector(ne_canyons_5070_spat, "C:/rworking/deepseatools/indata/ne_canyons_5070.shp", overwrite = TRUE)


##### check ##### 
# st_crs(ne_canyons)

```

```{r import_Hudson_bathy, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=T, }

# Define the GeoTIFF file path
geotiff_path <- "C:/rworking/deepseatools/indata/hc_rb_bath100/hc_rb_bath100.tif"

# Read the raster data
bathy_hudson <- rast(geotiff_path)

# Reproject the raster to the target_crs
bathy_hudson_5070 <- project(bathy_hudson, "EPSG:5070")

##### write the raster (OPTIONAL) ##### 
writeRaster(bathy_hudson_5070, "c:/rworking/deepseatools/indata/bathy_hudson_5070.tif", overwrite = TRUE)


```

```{r import_Hudson_facies, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=T, }

##### get the Hudson facies ##### 
shapefile_path <- "C:/rworking/deepseatools/indata/hc_facies/hc_facies.shp"
hc_facies <- st_read(shapefile_path)

##### reproject to target crs ##### 
hc_facies_5070 <- st_transform(hc_facies, crs = 5070)

##### check ##### 
# st_crs(hc_facies)
# plot(hc_facies)
# names(hc_facies)
# table(hc_facies$INTERP)

```

```{r make_AOI, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=T, }

# Get the bounding box as a SpatVector
aoi <- ext(hc_facies_5070) %>% as.polygons(crs = crs(hc_facies_5070))

# Save the bounding box as a shapefile
writeVector(aoi, "c:/rworking/deepseatools/indata/aoi.shp", overwrite = TRUE)

```

```{r import_noaa_bathy, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=T, }

library(marmap)

# Define bounding box
lon_min <- -68.68
lon_max <- -65.59
lat_min <- 38.776
lat_max <- 40.766

# Get bathymetry data (default resolution: 4 arc-minutes ~7.4 km)
bathy_data <- getNOAA.bathy(lon1 = lon_min, lon2 = lon_max, lat1 = lat_min, lat2 = lat_max, resolution = 1)  # Use resolution = 1 for higher resolution (~1.8 km)

# Convert to raster and plot
bathy_raster <- as.raster(bathy_data)
plot(bathy_raster)

library(terra)

# Convert raster object to SpatRaster
bathy_ne_canyons <- rast(bathy_raster)

## reproject the raster 
bathy_ne_canyons_5070 <- project(bathy_ne_canyons, "EPSG:5070")

##### reclassify these rasters ##### 
# Define reclassification matrix for negative depth values
rcl_matrix <- matrix(c(
  -9999, -3000, 7,
  -3000, -2500, 6,
  -2500, -2000, 5,
  -2000, -1500, 4,
  -1500, -1000, 3,
  -1000, -500, 2,
  -500, 0, 1
), ncol = 3, byrow = TRUE)

# Reclassify the rasters
bathy_ne_canyons_reclassified <- classify(bathy_ne_canyons_5070, rcl_matrix)


# Plot results
# plot(crm1_reclassified)
# plot(crm2_reclassified)

##### write the raster (OPTIONAL) ##### 
writeRaster(bathy_ne_canyons_reclassified, "c:/rworking/deepseatools/indata/bathy_ne_canyons_reclassified.tif", overwrite = TRUE)
# writeRaster(crm2_reclassified, "c:/rworking/deepseatools/indata/crm2_reclassified_ne_canyons.tif", overwrite = TRUE)

##### check ##### 
freq(crm1_reclassified)
pixel_area <- prod(res(crm1_reclassified))  # Multiply x and y resolution
pixel_area






```

```{r import_CRM_subset_reclass, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=F, }
##### get data from here ##### 
## https://www.ngdc.noaa.gov/thredds/catalog/crm/cudem/catalog.html
##### load CRM data #####
crm1 <- rast("C:/rworking/deepseatools/indata/crm/crm_vol1_2023.nc")
crm2 <- rast("C:/rworking/deepseatools/indata/crm/crm_vol2_2023.nc")
ext(crm1)
##### crop crm1 to NE Canyons and Seamounts ##### 
custom_extent <- ext(-68.68, -65.59, 39, 41)
ne_canyons_cropped <- crop(crm1, custom_extent)

##### crop crm1 to hudson ##### 
custom_extent <- ext(-72.65, -68.66, 39, 40.28)
hudson1_cropped <- crop(crm1, custom_extent)

##### crop crm2 to hudson ##### 
custom_extent <- ext(-72.65, -70.133573, 37.4783, 40)
hudson2_cropped <- crop(crm2, custom_extent)

## reproject the raster 
hudson1_cropped_5070 <- project(hudson1_cropped, "EPSG:5070")
hudson2_cropped_5070 <- project(hudson2_cropped, "EPSG:5070")
ne_canyons_cropped_5070 <- project(ne_canyons_cropped, "EPSG:5070")

##### reclassify these rasters ##### 
# Define reclassification matrix for negative depth values
rcl_matrix <- matrix(c(
  -9999, -3000, 7,
  -3000, -2500, 6,
  -2500, -2000, 5,
  -2000, -1500, 4,
  -1500, -1000, 3,
  -1000, -500, 2,
  -500, 0, 1
), ncol = 3, byrow = TRUE)

# Reclassify the rasters
hudson1_reclassified <- classify(hudson1_cropped_5070, rcl_matrix)
hudson2_reclassified <- classify(hudson2_cropped_5070, rcl_matrix)
ne_canyons_reclassified <- classify(ne_canyons_cropped_5070, rcl_matrix)

# Plot results
# plot(crm1_reclassified)
# plot(crm2_reclassified)

##### write the raster (OPTIONAL) ##### 
writeRaster(hudson1_reclassified, "c:/rworking/deepseatools/indata/hudson1_reclassified.tif", overwrite = TRUE)
writeRaster(hudson2_reclassified, "c:/rworking/deepseatools/indata/hudson2_reclassified.tif", overwrite = TRUE)
writeRaster(ne_canyons_reclassified, "c:/rworking/deepseatools/indata/ne_canyons_reclassified.tif", overwrite = TRUE)

##### check ##### 
# freq(crm1_reclassified)
# pixel_area <- prod(res(crm1_reclassified))  # Multiply x and y resolution
# pixel_area

```

```{r buffering, echo=F}
##### buffer operations ##### 
## create 5000 meter buffer
ne_canyons_buf_5000 <- st_buffer(ne_canyons, dist=5000) # map units are in meters

##create 20000 meter buffer
ne_canyons_buf_20000 <- st_buffer(ne_canyons, dist=20000) # map units are in meters

## check
# plot(ne_canyons_buf_20000)

```

```{r intersect, echo=F}
##### intersection operations ##### 
## transform CRS for coral and sponge points projection to match polygons
points_transform <- st_transform(points, crs = st_crs(ne_canyons))

## checking
# st_crs(points_transform)

## find points within the polygons
points_in_0 <- st_join(points_transform, ne_canyons, join = st_within) # no buffer
points_in_5000 <- st_join(points_transform, ne_canyons_buf_5000, join = st_within) # 5000 meter buffer
points_in_20000 <- st_join(points_transform, ne_canyons_buf_20000, join = st_within) # 20000 meter buffer

## checking
# dim(points_in_0)
# dim(points_in_5000)
# dim(points_in_20000)
# table(points_in_0$Shape_Area, useNA = 'always')
# table(points_in_5000$Shape_Area, useNA = 'always')
# table(points_in_20000$Shape_Area, useNA = 'always')

## select intersecting points only and create separate data frames
points_in_0_select <- points_in_0 %>% filter(is.na(Shape_Area) == F)
points_in_5000_select <- points_in_5000 %>% filter(is.na(Shape_Area) == F)
points_in_20000_select <- points_in_20000 %>% filter(is.na(Shape_Area) == F)

## checking 
# dim(points_in_0_select)
# dim(points_in_5000_select)
# dim(points_in_20000_select)


```

```{r get_obis_data, cache=T, echo=F, eval=F} 
##### getting OBIS data #####
## first get the original projection back (this CRS is what OBIS and GBIF expect)
## ID["EPSG",6326]]
ne_canyons_transform <- st_transform(ne_canyons, crs = st_crs(x_geo))
ne_canyons_transform <- st_make_valid(ne_canyons_transform)
ne_canyons_transform_wkt <- sf::st_as_text(sf::st_geometry(ne_canyons_transform))

## using bounding box variables defined above in another chunk
library(spocc)
out <- occ(geometry = ne_canyons_transform_wkt, from = 'obis', limit = 10000)
obis <- as.data.frame(out$obis$data)


## Convert to sf object using coordinates
obis_sf <- st_as_sf(
  obis,
  coords = c("longitude", "latitude"), # specify coordinate columns
  crs = 4326                         # set CRS to WGS84 (EPSG:4326)
)

## check 
# dim(obis)
# View(obis)
# names(obis)
# table(obis$catalogNumber)
# table(obis$id)
# table(obis$aphiaID)
# plot(obis_sf)

```

```{r export_to_local, echo=F, eval=F}
# export data files to local folder
##### export Excel file of data records to folder #####
setwd("C:/rworking/deepseatools/indata")
write.csv(as.data.frame(points_in_0_select),'DSCRTP_AOI_no_buffer.csv')
write.xlsx(as.data.frame(obis),'OBIS_AOI_no_buffer.xlsx')

```

```{r records_with_images, echo=F}
z <- points_in_0_select %>% filter(is.na(ImageURL) == F) %>% pull(ImageURL) %>% unique() %>% length()

```

# Purpose of Report

To create summaries of occurrence data to support decision making in the Northeast Canyons and Seamounts Marine National Monument.    

# Online Resources

The source RMarkdown code used to generate this report is linked here on GitHub: [LINK](https://github.com/RobertMcGuinn/deepseatools/blob/master/code/20250310-0_NE_Canyons_Monument_143822.Rmd)

# Methods

Coral and sponge occurrences from NOAA National Database for Deep-sea Corals and Sponges and other occurrences from the Ocean Biogeographic Information System (OBIS) are summarized within the NE Canyons Monument Area of Interest (AOI).

Version Notes: The National Database was accessed at version number `r db_version`. The OBIS database was last accessed 2025-03-10.   

# Maps

Occurrences from the National Database that intersect AOI

```{r plot_NDB, fig.width=6, fig.height=4, dpi=300, echo = F}

## plot to see how they relate
ggplot() +
  # Add layers with legend mappings
  # geom_sf(data = oculina, aes(fill = "Oculina Banks HAPC"), alpha = 0.3) +
  # geom_sf(data = ne_canyons_buf_20000, aes(fill = "NE Canyons Monument-AOI + 20 km buffer"), alpha = 0.3) +
  
  geom_sf(data = ne_canyons, aes(fill = "NE Canyons and Seamounts"), alpha = .5) +
  
  geom_sf(data = points_in_0_select, aes(color = "National Database")) +
  
  # Custom legend labels and colors
  scale_fill_manual(
    name = "AOI",
    values = c("NE Canyons and Seamounts" = "red" )
  ) +
  scale_color_manual(
    name = "Occurrences",
    values = c("National Database" = "black")
  ) +
  
  # Minimal theme and optional adjustments
  theme_minimal() +
  theme(
    legend.position = "right",                # Place legend on the right
    axis.text.x = element_text(angle = 90)   # Rotate x-axis labels (if applicable)
  )


```
Occurrences from OBIS that intersect the AOI

```{r plot_OBIS, fig.width=6, fig.height=4, dpi=300, echo = F}
## plot to see how they relate
ggplot() +
  # Add layers with legend mappings
  # geom_sf(data = oculina, aes(fill = "Oculina Banks HAPC"), alpha = 0.3) +
  # geom_sf(data = ne_canyons_buf_20000, aes(fill = "NE Canyons Monument-AOI + 20 km buffer"), alpha = 0.3) +
  
  geom_sf(data = ne_canyons, aes(fill = "NE Canyons and Seamounts Monument"), alpha = .5) +
  
  geom_sf(data = obis_sf, aes(color = "OBIS")) +
  
  # Custom legend labels and colors
  scale_fill_manual(
    name = "AOI",
    values = c("NE Canyons and Seamounts Monument" = "red" )
  ) +
  scale_color_manual(
    name = "Occurrences",
    values = c("OBIS" = "black")
  ) +
  
  # Minimal theme and optional adjustments
  theme_minimal() +
  theme(
    legend.position = "right",                # Place legend on the right
    axis.text.x = element_text(angle = 90)   # Rotate x-axis labels (if applicable)
  )


```

# Results

## Taxa within the AOI (no buffer) from the DSCRTP NOAA National Database for Deep-sea Corals and Sponges

Number of occurrences within the AOI: `r length(points_in_0_select$CatalogNumber)`

### Table of Taxa Grouped by 'VernacularNameCategory' 

``` {r CoralByVernacularNameCategoryTarget, echo=FALSE }
target <- as.data.frame(points_in_0_select)

sum_tbl <-
  target %>%
  # filter(Phylum == "Cnidaria") %>% 
  group_by(VernacularNameCategory) %>%
  summarize(
    Taxa = toString(unique(ScientificName)),
    Records = n()) %>%
  arrange(desc(Records))
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2)
sum_tbl

```

### Dataset Details from the National Database

``` {r Expedition_details_no_buf, echo=FALSE }

target <- as.data.frame(points_in_0_select)

sum_tbl <-
  target %>%
  group_by(DatasetID) %>%
  summarize(Vessel = toString(unique(Vessel)),
            #SurveyID = toString(unique(SurveyID)),
            SamplingEquipment = toString(unique(SamplingEquipment)),
            RecordType = toString(unique(RecordType)),
            #BeginYear= min(as.numeric(ObservationYear)),
            EndYear= max(as.numeric(ObservationYear)),
            n = prettyNum(n(),big.mark = ',')) %>% 
  arrange(desc(DatasetID))

sum_tbl$url <- paste0('https://www.ncei.noaa.gov/waf/dsc-data/dashboards/',
                      sum_tbl$DatasetID, 
                      '.html', 
                      sep = '')

sum_tbl$DashBoard <- paste0("[", "Dashboard Link", "](", sum_tbl$url, ")")
sum_tbl <- sum_tbl %>% dplyr::select(-url)
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2)
sum_tbl


```

``` {r EventID_details_no_buf, echo=FALSE }

sum_tbl <-
  points_in_0_select %>%
  group_by(DatasetID, SurveyID, EventID) %>%
  summarize(Vessel = toString(unique(Vessel)),
            Minimum_Depth = min(MinimumDepthInMeters),
            Maximum_Depth = max(MaximumDepthInMeters),
            BeginYear= min(as.numeric(ObservationYear), na.rm = T),
            n = prettyNum(n(),big.mark = ',')) %>% 
  arrange(desc(DatasetID))

sum_tbl$url <- paste0('https://www.ncei.noaa.gov/waf/dsc-data/dashboards/',
                      sum_tbl$DatasetID, 
                      '.html', 
                      sep = '')

sum_tbl$DashBoard <- paste0("[", "Dashboard Link", "](", sum_tbl$url, ")")
sum_tbl <- sum_tbl %>% dplyr::select(-url)
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2)
sum_tbl


```



## Taxa within the AOI (no buffer) from OBIS

Number of occurrences within the AOI: `r length(obis$datasetName)`. (NOTE: The OBIS API limit is 10,000, so more records may exist if limit is reached.)

### Table of Taxa Grouped by Order

``` {r TaxaByOrderTargetOBIS, echo=FALSE }

sum_tbl <-
  obis %>%
  group_by(order) %>%
  summarize(
    Taxa = toString(unique(name)),
    Records = n()) %>%
  arrange(desc(Records))
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2)
sum_tbl

```

### Dataset Details (OBIS)

``` {r Expedition_details_obis, echo=FALSE }
sum_tbl <-
  obis %>%
  group_by(dataset_id) %>%
  summarize(
    Records = n()
  ) %>%
  mutate(
    OBIS_Dataset = paste('https://obis.org/dataset/', dataset_id, sep = '') 
  ) %>%
  dplyr::select(OBIS_Dataset,Records) %>% 
  arrange(desc(Records))

sum_tbl <- kable(sum_tbl, row.names = FALSE, digits = 2)
sum_tbl


```
### Average Sampling Depth by Dataset (OBIS)

``` {r depth_distribution_obis, echo=FALSE }
sum_tbl <-
  obis %>%
  mutate(OBIS_Dataset = paste('https://obis.org/dataset/', dataset_id, sep = '')) %>%
  group_by(OBIS_Dataset) %>%
  summarize(minDepthInMeters = min(minimumDepthInMeters, na.rm = T),
            maxDepthInMeters = max(maximumDepthInMeters, na.rm = T),
            Records = n()) %>% 
  arrange(desc(Records))
         
sum_tbl <- kable(sum_tbl, row.names = FALSE, digits = 2)
sum_tbl

```

## Images from the National Database within the AOI

We have `r z` unique images which can be uploaded to Google Drive on request. (contact: Robert.McGuinn@NOAA.gov)

```{r load_images_to_local_folder, echo =F, eval=F}
## load any images to a local folder 
#### WARNING: This chunk takes a long time.  Go get a coffee #####
###### download all images and put them in a folder #####
z <- points_in_0_select %>% filter(is.na(ImageURL) == F)

## check 
length(z$ImageFilePath) # if this is zero, then the code below will return nothing

## manual: change directory to send images
dir.create('C:/rworking/deepseatools/indata/ne_canyons_images', recursive = TRUE)
setwd("C:/rworking/deepseatools/indata/ne_canyons_images")

## loop to download images 
for(i in 1:length(z$CatalogNumber)){
  download.file(as.character(z$ImageURL[i]),
                destfile = paste("DSCRTP",
                                 z$CatalogNumber[i],
                                 z$ScientificName[i],
                                 z$DepthInMeters[i],
                                 basename(as.character(z$ImageURL[i])),
                                 sep = '_'),
                mode = "wb")
}

```

```{r load_images_to_google_drive, echo=F, eval=F}
# load the images to a Google Drive folder
## WARNING: This chunk could take a longish time. Go get a coffee

##### Loading files from a local folder to Google Drive ##### 
## MANUAL CHANGE "folderurl" to the desired drive folder ID
folderurl <- "https://drive.google.com/drive/folders/1oOiCVRWJUc4fQQ1dec9q3APYfk1Ea4nj"

## get the list of files from the local folder
files <- list.files(path="C:/rworking/deepseatools/indata/imageset_5000", full.names=TRUE, recursive=FALSE)

## loop upload images to Google Drive
for(i in files){
drive_upload(i,
             path = as_id(folderurl),
             overwrite = T)
}

```

``` {r depth_db, echo=FALSE}
##### make depth box-plots #####
sub <- points_in_0_select
ylower <- 0
yupper <- 4000

sub <- points_in_0_select %>% filter(is.na(FishCouncilRegion) == F,
                       as.numeric(DepthInMeters) < yupper,
                       as.numeric(DepthInMeters) > ylower,
                       is.na(VernacularNameCategory) == F)

sub$DepthCat4[sub$DepthInMeters < 300] <- "< 300 m"
sub$DepthCat4[sub$DepthInMeters > 300 & sub$DepthInMeters <= 600] <- "300-600 m"
sub$DepthCat4[sub$DepthInMeters > 600 & sub$DepthInMeters <= 1000] <- "600-1000 m"
sub$DepthCat4[sub$DepthInMeters > 1000] <- "> 1000 m"
sub$DepthCat4 <- factor(sub$DepthCat4, levels = c("< 300 m", "300-600 m","600-1000 m", "> 1000 m" ))

list <- unique(sub$DepthCat4)
sub$VernacularNameCategory <- as.factor(sub$VernacularNameCategory)

## original color pallette for DSCRTP
# "stony coral (branching)" =  "#FFFFFF",
# "stony coral (cup coral)" =  "#00E6A9",
# "black coral" =  "#000000",
# "gorgonian coral" = "#FF0000",
# "soft coral" =  "#00734C",
# "sea pen" = "#0000FF",
# "stoloniferan coral" = "#7F7F7F",
# "lace coral" = "#A80084",
# "lithotelestid coral" = "#FF00C5",
# "stony coral (unspecified)" = "#D1FF73",
# "gold coral" =  "#FFFF00",
# "sponge (unspecified)" = "#FF0000",
# "demosponge" = "#00FFC5",
# "glass sponge" = "#C500FF",
# "homoscleromorph sponge" = "#FFFF00",
# "calcareous sponge" = "#55FF00",
# "other coral-like hydrozoan" = "#00FFFF",
# "alcyonacean (unspecified)" = "#D7B09E"


my_colors <- c(
"stony coral (branching)" =  "#FFFFFF",
"stony coral (cup coral)" =  "#00E6A9",
"black coral" =  "#000000",
"gorgonian coral" = "#FF0000",
"soft coral" =  "#00734C",
"sea pen" = "#0000FF",
"stoloniferan coral" = "#7F7F7F",
"lace coral" = "#A80084",
"lithotelestid coral" = "#FF00C5",
"stony coral (unspecified)" = "#D1FF73",
"gold coral" =  "#FFFF00",
"sponge (unspecified)" = "#FF0000",
"demosponge" = "#00FFC5",
"glass sponge" = "#C500FF",
"homoscleromorph sponge" = "#FFFF00",
"calcareous sponge" = "#55FF00",
"other coral-like hydrozoan" = "#00FFFF",
"alcyonacean (unspecified)" = "#D7B09E",
"fish" = "#7a2d0a"
)

for(i in list){
  x <- sub %>% filter(DepthCat4 == i)
  g <- ggplot(x, aes(reorder(VernacularNameCategory, DepthInMeters, FUN=median),
                     as.numeric(DepthInMeters),
                     fill = VernacularNameCategory)) +
    geom_boxplot() +
    scale_y_reverse() +
    ylab("Depth (meters)") +
    xlab("Vernacular Name Category") +
    theme_bw(base_size = 13, base_family = "Cambria") +
    theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1, face = 'italic'),
          axis.title.y = element_text(margin = margin(r = 30))) +
    scale_fill_manual(values = my_colors) +
    labs(fill = "Vernacular Name Category")


  ggsave(paste("c:/rworking/deepseatools/images/NE/",
               "202505311_",
               "NatDB_",
               unique(sub$DatabaseVersion),
               '_',
               i,
               ".png",
               sep = ''),
         width = 10,
         height = 6,
         units = "in")
}


```
