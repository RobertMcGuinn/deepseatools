---
title: "Area of Interest Report - Northeast Canyons and Seamounts National Monument"
author: "Robert P. McGuinn"
date: "April 2, 2025"
output: word_document
---

```{r packages, eval=T, echo=F, message=FALSE, warning=FALSE, cache=FALSE}
## load packages
#install.packages(tidyverse)
#install.packages('openxlsx')
library(tidyverse)
library(openxlsx)
library(sf)
library(RColorBrewer)
library(raster)
library(leaflet)
library(extrafont)
loadfonts()
library(RColorBrewer)
library(rmarkdown)
library(knitr)
library(maps)
library(raster)
library(httr)
library(jsonlite)
library(rnaturalearth)
library(rnaturalearthdata)
library(openxlsx)
library(googledrive)
library(spocc)
library(terra)
library(knitr)
library(kableExtra)

```

```{r load_NDB, echo=F, message = FALSE, warning = FALSE, cache = TRUE, eval = T}
## load NDB
source('c:/rworking/deepseatools/code/mod_load_current_NDB.R')

```

```{r set_ndb_version, echo=F, eval=T}
## create needed variables
db_version <- unique(filt$DatabaseVersion)

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      fig.height = 4.5,
                      fig.width = 7.5
                      )

```

```{r filter_points_by_geography, echo=F, warning=F, message=F, eval=T}
##### filter occurrences by query or box or both ##### 
## set bounding box variables
minlat <- 37
maxlat <- 41
minlon <- -73
maxlon <- -65

## subset data by coordinates
x <- subset(filt, as.numeric(Latitude) > minlat &
                   as.numeric(Latitude) < maxlat &
                   as.numeric(Longitude) > minlon &
                   as.numeric(Longitude) < maxlon)
                
## also subset data by other variables by other criteria
# x <- x %>% filter(ScientificName == "")

## checking
# dim(x)

```

```{r create_geo_from_points, echo=FALSE, echo = FALSE, message = FALSE, warning=FALSE, eval=T}
## create spatial points data frame from a subset of points
x_geo <- x

## create spdf
coordinates(x_geo) <- c("Longitude", "Latitude")
proj4string(x_geo) <- "+proj=longlat +ellps=WGS84 +datum=WGS84"

## OPTIONAL: write out featureclass to geodatabase from sp object 
# fgdb_path <- "C:/data/aprx/aoi/aoi.gdb"
# arc.write(file.path(fgdb_path, 'x_geo'), data=x_geo, overwrite = TRUE)

```

```{r create_sf_from_points, message = FALSE, warning = FALSE, echo=T}
##### transform coral and sponge points to sf #####
points <- st_as_sf(x_geo, wkt = "geom")

##### write points for portal ##### 
fish_points_for_app <- 
  points %>% filter(Phylum == 'Chordata') %>% 
  dplyr::select(CatalogNumber,
                Class, 
                Order,
                Family, 
                ScientificName, Vessel, 
                SurveyID, 
                ObservationDate, 
                PI, 
                DatasetID, 
                DataProvider)
st_write(fish_points_for_app, "c:/rworking/deepseatools/indata/fish_points_for_app.shp", overwrite = TRUE)

fish_points_for_app %>% pull(Family) %>% table(useNA = 'always')

```

```{r import_NE_Canyons_aoi, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=T, }

##### get the NE Canyons mounument ##### 
shapefile_path <- "C:/rworking/deepseatools/indata/20221104_protected_areas_update_HColeman/20221104_protected_areas.shp"
protected_areas <- st_read(shapefile_path)
ne_canyons <- protected_areas %>% filter(Sitename == 'NE Canyons and Seamounts')

##### reproject to target crs ##### 
ne_canyons_5070 <- st_transform(ne_canyons, crs = 5070)

##### Convert sf to SpatVector ##### 
ne_canyons_5070_spat <- vect(ne_canyons_5070)

##### Write to shapefile #####
# writeVector(ne_canyons_5070_spat, "C:/rworking/deepseatools/indata/ne_canyons_5070.shp", overwrite = TRUE)


##### check ##### 
# st_crs(ne_canyons)

```

```{r import_Hudson_bathy, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=T, }

# Define the GeoTIFF file path
geotiff_path <- "C:/rworking/deepseatools/indata/hc_rb_bath100/hc_rb_bath100.tif"

# Read the raster data
bathy_hudson <- rast(geotiff_path)

# Reproject the raster to the target_crs
bathy_hudson_5070 <- project(bathy_hudson, "EPSG:5070")

##### write the raster (OPTIONAL) ##### 
writeRaster(bathy_hudson_5070, "c:/rworking/deepseatools/indata/bathy_hudson_5070.tif", overwrite = TRUE)


```

```{r import_Hudson_facies, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=F }

##### get the Hudson facies ##### 
shapefile_path <- "C:/rworking/deepseatools/indata/hc_facies/hc_facies.shp"
hc_facies <- st_read(shapefile_path)

##### reproject to target crs ##### 
hc_facies_5070 <- st_transform(hc_facies, crs = 5070)

##### check ##### 
# st_crs(hc_facies)
# plot(hc_facies)
# names(hc_facies)
# table(hc_facies$INTERP)

```

```{r make_AOI, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=T, }

# Get the bounding box as a SpatVector
hudson_aoi_bbox <- ext(hc_facies_5070) %>% as.polygons(crs = crs(hc_facies_5070))

# Save the bounding box as a shapefile
writeVector(hudson_aoi_bbox, "c:/rworking/deepseatools/indata/aoi.shp", overwrite = TRUE)

```

```{r import_noaa_bathy, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=F, }

library(marmap)

# Define bounding box
lon_min <- -68.68
lon_max <- -65.59
lat_min <- 38.776
lat_max <- 40.766

# Get bathymetry data (default resolution: 4 arc-minutes ~7.4 km)
bathy_data <- getNOAA.bathy(lon1 = lon_min, lon2 = lon_max, lat1 = lat_min, lat2 = lat_max, resolution = 1)  # Use resolution = 1 for higher resolution (~1.8 km)

# Convert to raster and plot
bathy_raster <- as.raster(bathy_data)
plot(bathy_raster)

library(terra)

# Convert raster object to SpatRaster
bathy_ne_canyons <- rast(bathy_raster)

## reproject the raster 
bathy_ne_canyons_5070 <- project(bathy_ne_canyons, "EPSG:5070")

##### reclassify these rasters ##### 
# Define reclassification matrix for negative depth values
rcl_matrix <- matrix(c(
  -9999, -3000, 7,
  -3000, -2500, 6,
  -2500, -2000, 5,
  -2000, -1500, 4,
  -1500, -1000, 3,
  -1000, -500, 2,
  -500, 0, 1
), ncol = 3, byrow = TRUE)

# Reclassify the rasters
bathy_ne_canyons_reclassified <- classify(bathy_ne_canyons_5070, rcl_matrix)


# Plot results
# plot(crm1_reclassified)
# plot(crm2_reclassified)

##### write the raster (OPTIONAL) ##### 
writeRaster(bathy_ne_canyons_reclassified, "c:/rworking/deepseatools/indata/bathy_ne_canyons_reclassified.tif", overwrite = TRUE)
# writeRaster(crm2_reclassified, "c:/rworking/deepseatools/indata/crm2_reclassified_ne_canyons.tif", overwrite = TRUE)

##### check ##### 
# freq(bathy_ne_canyons_reclassified)
# pixel_area <- prod(res(bathy_ne_canyons_reclassified))  # Multiply x and y resolution
# pixel_area


```

```{r import_CRM_subset_reclass_combine, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=F, }
##### get data from here ##### 
## https://www.ngdc.noaa.gov/thredds/catalog/crm/cudem/catalog.html
##### load CRM data #####
crm1 <- rast("C:/rworking/deepseatools/indata/crm/crm_vol1_2023.nc")
crm2 <- rast("C:/rworking/deepseatools/indata/crm/crm_vol2_2023.nc")
ext(crm1)

##### crop crm1 to NE Canyons and Seamounts large AOI ##### 
## define custom extent: xmin, ymin, xmax, ymax
xmin <- -73
ymin <- 39
xmax <- -65
ymax <- 41

## create a box polygon from the custom extent
bbox <- st_as_sfc(st_bbox(c(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax), crs = 4326))  # Use appropriate CRS

## Convert to sf object
bbox_sf <- st_sf(geometry = bbox)

## Export to shapefile for visualization (OPTIONAL)
# st_write(bbox_sf, "c:/rworking/deepseatools/indata/custom_extent_box.shp", delete_layer = TRUE)

## reproject to make sure the vector crs matcheses the raster 
ne_canyons_proj <- st_transform(bbox_sf, crs(crm1))

## Clip the raster using the vector (crop first, then mask)
cropped_raster <- crop(crm1, ne_canyons_proj)
clipped_raster_ne <- mask(cropped_raster, ne_canyons_proj)

##### crop crm2 to Hudson Canyon southern extension ##### 
## define custom extent: xmin, ymin, xmax, ymax
xmin <- -73
ymin <- 37
xmax <- -68
ymax <- 39

## create a box polygon from the custom extent
bbox <- st_as_sfc(st_bbox(c(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax), crs = 4326))  # Use appropriate CRS

## Convert to sf object
bbox_sf <- st_sf(geometry = bbox)

## Export to shapefile for visualization (OPTIONAL)
# st_write(bbox_sf, "c:/rworking/deepseatools/indata/custom_extent_box.shp", delete_layer = TRUE)

## reproject to make sure the vector crs matcheses the raster 
hudson_proj <- st_transform(bbox_sf, crs(crm2))

## Clip the raster using the vector (crop first, then mask)
cropped_raster <- crop(crm2, hudson_proj)
clipped_raster_hudson <- mask(cropped_raster, hudson_proj)

##### reclassify these rasters ##### 
library(terra)

# Define reclassification matrix for negative depth values
rcl_matrix <- matrix(c(
  -9999, -3000, 7,
  -3000, -2500, 6,
  -2500, -2000, 5,
  -2000, -1500, 4,
  -1500, -1000, 3,
  -1000, -500, 2,
  -500, 0, 1, 
  0, 1000, -999
), ncol = 3, byrow = TRUE)

# Perform reclassification
crm_reclass_7_ne <- classify(clipped_raster_ne, rcl_matrix)
crm_reclass_7_hudson <- classify(clipped_raster_hudson, rcl_matrix)

##### combine the rasters in to one ##### 
combined_raster <- mosaic(crm_reclass_7_ne, crm_reclass_7_hudson, fun = "max")

##### write the combined raster for visualization ##### 
writeRaster(
  combined_raster,
  filename = "c:/rworking/deepseatools/indata/crm_reclass_7_combined.tif",
  datatype = "INT2S",        # Ensures integer data
  overwrite = TRUE
)

```

```{r import_GEBCO_2024_data, echo=FALSE, echo = F, message = FALSE, warning=FALSE, results = "hide", eval=F, }
## get data from here: https://download.gebco.net/ (aquired 20250404)
## use this bounding box to subset
##  West	East	South	North
# -73	-65	37	41

gebco_2024_bathy <- rast("C:/rworking/deepseatools/indata/GEBCO_04_Apr_2025_1594a0e93d89/gebco_2024_n41.0_s37.0_w-73.0_e-65.0.tif")

# Define reclassification matrix for negative depth values
rcl_matrix <- matrix(c(
  -9999, -3000, 13,
  -3000, -2750, 12,
  -2750, -2500, 11,
  -2500, -2250, 10,
  -2250, -2000, 9,
  -2000, -1750, 8,
  -1750, -1500, 7,
  -1500, -1250, 6,
  -1250, -1000, 5,
  -1000, -750, 4,
  -750, -500, 3,
  -500, -250, 2,
  -250, 0, 1,
  0, 1000, -999
), ncol = 3, byrow = TRUE)

# rcl_matrix <- matrix(c(
#   -9999, -3000, 7,
#   -3000, -2500, 6,
#   -2500, -2000, 5,
#   -2000, -1500, 4,
#   -750, -500, 3,
#   -500, -250, 2,
#   -250, 0, 1, 
#   0, 1000, -999
# ), ncol = 3, byrow = TRUE)

# Perform reclassification
gebco_2024_bathy_reclass <- classify(gebco_2024_bathy, rcl_matrix)

##### write the combined raster for visualization ##### 
writeRaster(
  gebco_2024_bathy_reclass,
  filename = "c:/rworking/deepseatools/indata/gebco_2024_bathy_reclass_250.tif",
  datatype = "INT2S",        # Ensures integer data
  overwrite = TRUE
)

```

```{r buffering, echo=F}
##### buffer operations ##### 
## create 5000 meter buffer
ne_canyons_buf_5000 <- st_buffer(ne_canyons_5070, dist=5000) # map units are in meters

##create 20000 meter buffer
ne_canyons_buf_20000 <- st_buffer(ne_canyons_5070, dist=20000) # map units are in meters

## check
# plot(ne_canyons_buf_20000)

```

```{r intersect, echo=F}
##### intersection operations ##### 
## transform CRS for coral and sponge points projection to match polygons
points_transform <- st_transform(points, crs = st_crs(ne_canyons_5070))

## checking
# st_crs(points_transform)

## find points within the polygons
points_in_0 <- st_join(points_transform, ne_canyons_5070, join = st_within) # no buffer
points_in_5000 <- st_join(points_transform, ne_canyons_buf_5000, join = st_within) # 5000 meter buffer
points_in_20000 <- st_join(points_transform, ne_canyons_buf_20000, join = st_within) # 20000 meter buffer

## checking
# dim(points_in_0)
# dim(points_in_5000)
# dim(points_in_20000)
# table(points_in_0$Shape_Area, useNA = 'always')
# table(points_in_5000$Shape_Area, useNA = 'always')
# table(points_in_20000$Shape_Area, useNA = 'always')

## select intersecting points only and create separate data frames
points_in_0_select <- points_in_0 %>% filter(is.na(Shape_Area) == F)
points_in_5000_select <- points_in_5000 %>% filter(is.na(Shape_Area) == F)
points_in_20000_select <- points_in_20000 %>% filter(is.na(Shape_Area) == F)

## checking 
# dim(points_in_0_select)
# dim(points_in_5000_select)
# dim(points_in_20000_select)


```

```{r intersect with classified raster, echo=F}

##### Extract raster values at point locations ##### 
# Convert sf object to SpatVector for terra
points_vect <- vect(points)

# Extract values
extracted <- extract(gebco_2024_bathy_reclass, points_vect)

# Add extracted values to the original point data
points$Classes <- extracted[, 2]  # The second column usually holds the raster values

# Save the new point file with class info
st_write(points_for_app, "c:/rworking/deepseatools/indata/points_with_classes2.shp", delete_dsn = TRUE)

class(points_for_app$Classes)


```

```{r get_obis_data, cache=T, echo=F, eval=F} 
##### getting OBIS data #####
## first get the original projection back (this CRS is what OBIS and GBIF expect)
## ID["EPSG",6326]]
ne_canyons_transform <- st_transform(ne_canyons, crs = st_crs(x_geo))
ne_canyons_transform <- st_make_valid(ne_canyons_transform)
ne_canyons_transform_wkt <- sf::st_as_text(sf::st_geometry(ne_canyons_transform))

## using bounding box variables defined above in another chunk
library(spocc)
out <- occ(geometry = ne_canyons_transform_wkt, from = 'obis', limit = 10000)
obis <- as.data.frame(out$obis$data)


## Convert to sf object using coordinates
obis_sf <- st_as_sf(
  obis,
  coords = c("longitude", "latitude"), # specify coordinate columns
  crs = 4326                         # set CRS to WGS84 (EPSG:4326)
)

## check 
# dim(obis)
# View(obis)
# names(obis)
# table(obis$catalogNumber)
# table(obis$id)
# table(obis$aphiaID)
# plot(obis_sf)

```

```{r export_to_local, echo=F, eval=F}
# export data files to local folder
##### export Excel file of data records to folder #####
setwd("C:/rworking/deepseatools/indata")
write.csv(as.data.frame(points_in_0_select),'DSCRTP_AOI_no_buffer.csv')
write.xlsx(as.data.frame(obis),'OBIS_AOI_no_buffer.xlsx')

```

```{r records_with_images, echo=F}
z <- points_in_0_select %>% filter(is.na(ImageURL) == F) %>% pull(ImageURL) %>% unique() %>% length()

```

# Purpose of Report

To create summaries of occurrence data to support decision making in the Northeast Canyons and Seamounts Marine National Monument.    

# Online Resources

The source RMarkdown code used to generate this report is linked here on GitHub: [LINK](https://github.com/RobertMcGuinn/deepseatools/blob/master/code/20250310-0_NE_Canyons_Monument_143822.Rmd)

# Methods

Coral and sponge occurrences from NOAA National Database for Deep-sea Corals and Sponges and other occurrences from the Ocean Biogeographic Information System (OBIS) are summarized within the NE Canyons Monument Area of Interest (AOI).

Version Notes: The National Database was accessed at version number `r db_version`. The OBIS database was last accessed 2025-03-10.   

# Maps

Occurrences from the National Database that intersect AOI

```{r plot_NDB, fig.width=6, fig.height=4, dpi=300, echo = F}

## plot to see how they relate
ggplot() +
  # Add layers with legend mappings
  # geom_sf(data = oculina, aes(fill = "Oculina Banks HAPC"), alpha = 0.3) +
  # geom_sf(data = ne_canyons_buf_20000, aes(fill = "NE Canyons Monument-AOI + 20 km buffer"), alpha = 0.3) +
  
  geom_sf(data = ne_canyons, aes(fill = "NE Canyons and Seamounts"), alpha = .5) +
  
  geom_sf(data = points_in_0_select, aes(color = "National Database")) +
  
  # Custom legend labels and colors
  scale_fill_manual(
    name = "AOI",
    values = c("NE Canyons and Seamounts" = "red" )
  ) +
  scale_color_manual(
    name = "Occurrences",
    values = c("National Database" = "black")
  ) +
  
  # Minimal theme and optional adjustments
  theme_minimal() +
  theme(
    legend.position = "right",                # Place legend on the right
    axis.text.x = element_text(angle = 90)   # Rotate x-axis labels (if applicable)
  )


```

Occurrences from OBIS that intersect the AOI

```{r plot_OBIS, fig.width=6, fig.height=4, dpi=300, echo = F, eval=F}
## plot to see how they relate
ggplot() +
  # Add layers with legend mappings
  # geom_sf(data = oculina, aes(fill = "Oculina Banks HAPC"), alpha = 0.3) +
  # geom_sf(data = ne_canyons_buf_20000, aes(fill = "NE Canyons Monument-AOI + 20 km buffer"), alpha = 0.3) +
  
  geom_sf(data = ne_canyons, aes(fill = "NE Canyons and Seamounts Monument"), alpha = .5) +
  
  geom_sf(data = obis_sf, aes(color = "OBIS")) +
  
  # Custom legend labels and colors
  scale_fill_manual(
    name = "AOI",
    values = c("NE Canyons and Seamounts Monument" = "red" )
  ) +
  scale_color_manual(
    name = "Occurrences",
    values = c("OBIS" = "black")
  ) +
  
  # Minimal theme and optional adjustments
  theme_minimal() +
  theme(
    legend.position = "right",                # Place legend on the right
    axis.text.x = element_text(angle = 90)   # Rotate x-axis labels (if applicable)
  )


```

# Results

## Taxa within the AOI (no buffer) from the DSCRTP NOAA National Database for Deep-sea Corals and Sponges

Number of occurrences within the AOI: `r length(points_in_0_select$CatalogNumber)`

### Table of Taxa Grouped by 'VernacularNameCategory' 

``` {r CoralByVernacularNameCategoryTarget, echo=FALSE, eval = F}
target <- as.data.frame(points_in_0_select)

sum_tbl <-
  target %>%
  # filter(Phylum == "Cnidaria") %>% 
  group_by(VernacularNameCategory) %>%
  summarize(
    Taxa = toString(unique(ScientificName)),
    Records = n()) %>%
  arrange(desc(Records))
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2)
sum_tbl

```

### Dataset Details from the National Database

``` {r Expedition_details_no_buf, echo=FALSE, eval = F}

target <- as.data.frame(points_in_0_select)

sum_tbl <-
  target %>%
  group_by(DatasetID) %>%
  summarize(Vessel = toString(unique(Vessel)),
            #SurveyID = toString(unique(SurveyID)),
            SamplingEquipment = toString(unique(SamplingEquipment)),
            RecordType = toString(unique(RecordType)),
            #BeginYear= min(as.numeric(ObservationYear)),
            EndYear= max(as.numeric(ObservationYear)),
            n = prettyNum(n(),big.mark = ',')) %>% 
  arrange(desc(DatasetID))

sum_tbl$url <- paste0('https://www.ncei.noaa.gov/waf/dsc-data/dashboards/',
                      sum_tbl$DatasetID, 
                      '.html', 
                      sep = '')

sum_tbl$DashBoard <- paste0("[", "Dashboard Link", "](", sum_tbl$url, ")")
sum_tbl <- sum_tbl %>% dplyr::select(-url)
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2)
sum_tbl


```

``` {r EventID_details_no_buf, echo=FALSE, eval = F }

sum_tbl <-
  points_in_0_select %>%
  group_by(DatasetID, SurveyID, EventID) %>%
  summarize(Vessel = toString(unique(Vessel)),
            Minimum_Depth = min(MinimumDepthInMeters),
            Maximum_Depth = max(MaximumDepthInMeters),
            BeginYear= min(as.numeric(ObservationYear), na.rm = T),
            n = prettyNum(n(),big.mark = ',')) %>% 
  arrange(desc(DatasetID))

sum_tbl$url <- paste0('https://www.ncei.noaa.gov/waf/dsc-data/dashboards/',
                      sum_tbl$DatasetID, 
                      '.html', 
                      sep = '')

sum_tbl$DashBoard <- paste0("[", "Dashboard Link", "](", sum_tbl$url, ")")
sum_tbl <- sum_tbl %>% dplyr::select(-url)
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2)
sum_tbl


```

``` {r TaxaByOrderTargetOBIS, echo=FALSE, eval = F}

sum_tbl <-
  obis %>%
  group_by(order) %>%
  summarize(
    Taxa = toString(unique(name)),
    Records = n()) %>%
  arrange(desc(Records))
sum_tbl <- kable(sum_tbl, row.names = F, digits = 2)
sum_tbl

```

### Dataset Details (OBIS)

``` {r Expedition_details_obis, echo=FALSE, eval = F }
sum_tbl <-
  obis %>%
  group_by(dataset_id) %>%
  summarize(
    Records = n()
  ) %>%
  mutate(
    OBIS_Dataset = paste('https://obis.org/dataset/', dataset_id, sep = '') 
  ) %>%
  dplyr::select(OBIS_Dataset,Records) %>% 
  arrange(desc(Records))

sum_tbl <- kable(sum_tbl, row.names = FALSE, digits = 2)
sum_tbl


```
### Average Sampling Depth by Dataset (OBIS)

``` {r depth_distribution_obis, echo=FALSE, eval = F}
sum_tbl <-
  obis %>%
  mutate(OBIS_Dataset = paste('https://obis.org/dataset/', dataset_id, sep = '')) %>%
  group_by(OBIS_Dataset) %>%
  summarize(minDepthInMeters = min(minimumDepthInMeters, na.rm = T),
            maxDepthInMeters = max(maximumDepthInMeters, na.rm = T),
            Records = n()) %>% 
  arrange(desc(Records))
         
sum_tbl <- kable(sum_tbl, row.names = FALSE, digits = 2)
sum_tbl

```

## Images from the National Database within the AOI

We have `r z` unique images which can be uploaded to Google Drive on request. (contact: Robert.McGuinn@NOAA.gov)

```{r load_images_to_local_folder, echo =F, eval=F}
## load any images to a local folder 
#### WARNING: This chunk takes a long time.  Go get a coffee #####
###### download all images and put them in a folder #####
z <- points_in_0_select %>% filter(is.na(ImageURL) == F)

## check 
length(z$ImageFilePath) # if this is zero, then the code below will return nothing

## manual: change directory to send images
dir.create('C:/rworking/deepseatools/indata/ne_canyons_images', recursive = TRUE)
setwd("C:/rworking/deepseatools/indata/ne_canyons_images")

## loop to download images 
for(i in 1:length(z$CatalogNumber)){
  download.file(as.character(z$ImageURL[i]),
                destfile = paste("DSCRTP",
                                 z$CatalogNumber[i],
                                 z$ScientificName[i],
                                 z$DepthInMeters[i],
                                 basename(as.character(z$ImageURL[i])),
                                 sep = '_'),
                mode = "wb")
}

```

```{r load_images_to_google_drive, echo=F, eval=F}
# load the images to a Google Drive folder
## WARNING: This chunk could take a longish time. Go get a coffee

##### Loading files from a local folder to Google Drive ##### 
## MANUAL CHANGE "folderurl" to the desired drive folder ID
folderurl <- "https://drive.google.com/drive/folders/1oOiCVRWJUc4fQQ1dec9q3APYfk1Ea4nj"

## get the list of files from the local folder
files <- list.files(path="C:/rworking/deepseatools/indata/imageset_5000", full.names=TRUE, recursive=FALSE)

## loop upload images to Google Drive
for(i in files){
drive_upload(i,
             path = as_id(folderurl),
             overwrite = T)
}

```

# Exploring Depth Bins


``` {r depth_bin_manual, echo=FALSE, eval = F}
##### Make Depth Boxplots #####

# Filter data
sub <- points %>% 
  filter(!is.na(FishCouncilRegion),
         as.numeric(DepthInMeters) < yupper,
         as.numeric(DepthInMeters) > ylower,
         !is.na(VernacularNameCategory))

sub$VernacularNameCategory <- as.factor(sub$VernacularNameCategory)

# Set color choices
my_colors <- c(
  "stony coral (branching)" =  "#FFFFFF",
  "stony coral (cup coral)" =  "#00E6A9",
  "black coral" =  "#000000",
  "gorgonian coral" = "#FF0000",
  "soft coral" =  "#00734C",
  "sea pen" = "#0000FF",
  "stoloniferan coral" = "#7F7F7F",
  "lace coral" = "#A80084",
  "lithotelestid coral" = "#FF00C5",
  "stony coral (unspecified)" = "#D1FF73",
  "gold coral" =  "#FFFF00",
  "sponge (unspecified)" = "#FF0000",
  "demosponge" = "#00FFC5",
  "glass sponge" = "#C500FF",
  "homoscleromorph sponge" = "#FFFF00",
  "calcareous sponge" = "#55FF00",
  "other coral-like hydrozoan" = "#00FFFF",
  "alcyonacean (unspecified)" = "#D7B09E",
  "fish" = "#7a2d0a"
)

## Set depth range
mindepth <- 0
maxdepth <- 500

x <- sub %>% 
  filter(Classes == 1,
         as.numeric(DepthInMeters) > mindepth,
         as.numeric(DepthInMeters) < maxdepth)

## Generate boxplot
g <- ggplot(x, aes(reorder(VernacularNameCategory, DepthInMeters, FUN=median),
                   as.numeric(DepthInMeters),
                   fill = VernacularNameCategory)) +
  geom_boxplot() +
  scale_y_reverse() +
  ylab("Depth (meters)") +
  xlab("Vernacular Name Category") +
  ggtitle(paste("Depth Distribution by Vernacular Name Category (", mindepth, "-", maxdepth, " m)", sep = "")) +
  theme_bw(base_size = 13, base_family = "serif") +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1, face = 'italic'),
    axis.title.y = element_text(margin = margin(r = 30))
  ) +
  scale_fill_manual(values = my_colors) +
  labs(fill = "Vernacular Name Category")

## Show plot
g

## Set depth range
mindepth <- 0
maxdepth <- 500.1

x <- sub %>% 
  filter(Classes == 1,
         as.numeric(DepthInMeters) > mindepth,
         as.numeric(DepthInMeters) < maxdepth)

## Generate boxplot
g <- ggplot(x, aes(reorder(VernacularNameCategory, DepthInMeters, FUN=median),
                   as.numeric(DepthInMeters),
                   fill = VernacularNameCategory)) +
  geom_boxplot() +
  scale_y_reverse() +
  ylab("Depth (meters)") +
  xlab("Vernacular Name Category") +
  ggtitle(paste("Depth Distribution by Vernacular Name Category (", mindepth, "-", maxdepth, " m)", sep = "")) +
  theme_bw(base_size = 13, base_family = "serif") +
  theme(
    axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1, face = 'italic'),
    axis.title.y = element_text(margin = margin(r = 30))
  ) +
  scale_fill_manual(values = my_colors) +
  labs(fill = "Vernacular Name Category")

## Show plot
g

```


``` {r depth_bin_loop_with_table, echo=FALSE}
##### Loop to make boxplots every 500 m #####

# Set depth bins
depth_bins <- seq(0, max(as.numeric(sub$DepthInMeters), na.rm = TRUE), by = 500)

# Loop through bins
for(i in 1:(length(depth_bins)-1)) {
  
  mindepth <- depth_bins[i]
  maxdepth <- depth_bins[i+1]
  
  x <- sub %>% 
    filter(as.numeric(DepthInMeters) > mindepth,
           as.numeric(DepthInMeters) <= maxdepth)
  
  if(nrow(x) > 0) {  # Only plot if data exists in that bin
    
    g <- ggplot(x, aes(reorder(VernacularNameCategory, DepthInMeters, FUN=median),
                       as.numeric(DepthInMeters),
                       fill = VernacularNameCategory)) +
      geom_boxplot() +
      scale_y_reverse() +
      ylab("Depth (meters)") +
      xlab("Vernacular Name Category") +
      ggtitle(sprintf("Depth Distribution by Category (%d-%d m)", mindepth, maxdepth)) +
      theme_bw(base_size = 13, base_family = "serif") +
      theme(
        axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1, face = 'italic'),
        axis.title.y = element_text(margin = margin(r = 30))
      ) +
      scale_fill_manual(values = my_colors) +
      labs(fill = "Vernacular Name Category")
    
    print(g)
    
    # Optional: Save each plot
    ggsave(sprintf("c:/rworking/deepseatools/images/NE/depth_boxplot_%dm_%dm.png", mindepth, maxdepth), g, width = 12, height = 6, dpi = 300)
    
    # Summary Table
    tab <- x %>%
      group_by(VernacularNameCategory) %>%
      summarise(
        N = n(),
        MinDepth = min(as.numeric(DepthInMeters), na.rm = TRUE),
        MedianDepth = median(as.numeric(DepthInMeters), na.rm = TRUE),
        MaxDepth = max(as.numeric(DepthInMeters), na.rm = TRUE), 
        ScientificNames = paste(unique(ScientificName), collapse = " / ")
      ) %>%
      arrange(MedianDepth)
    
    kable(tab, caption = sprintf("Depth Summary Table (%d-%d m)", mindepth, maxdepth)) %>%
      kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
    
  
  }
}

```



