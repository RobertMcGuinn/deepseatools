##### Header #####
## Author: Robert P. McGuinn
## Date started: 2025-10-06
## Purpose: Runner for RMarkdown report: dashboards for each DatasetID.
## NOTE: 4 groups: Cruise, Literature, Program, Repository, and then Repository-MBARI

##### install packages #####
library(sf)
library(sp)
library(openxlsx)
library(tidyverse)
library(RColorBrewer)
library(googledrive)
library(rmarkdown)
library(knitr)
library(maps)
library(prettydoc)
library(httr)
library(jsonlite)
library(rnaturalearth)
library(rnaturalearthdata)
library(googlesheets4)

##### authorizations #####
# Set authentication token to be stored in a folder called \.secrets``
options(gargle_oauth_cache = ".secrets")

## Authenticate manually
# gs4_auth()

## If successful, the previous step stores a token file.
## Check that a file has been created with:
# list.files(".secrets/")

## Check that the non-interactive authentication works by first deauthorizing:
# gs4_deauth()

# Authenticate using token. If no browser opens, the authentication works.
gs4_auth(cache = ".secrets", email = "robert.mcguinn@noaa.gov")
drive_auth(cache = ".secrets", email = "robert.mcguinn@noaa.gov")

##### set an option #####
options(lifecycle_disable_warnings = TRUE)

##### load current database from disk #####
source("c:/rworking/deepseatools/code/mod_load_current_ndb.R")

##### define database version (this variable called in RMD files) #####
version <- unique(filt$DatabaseVersion)
version <- as.character(version)

##### bring in current datasetID key from local path #####
# old_key <- read.xlsx("C:/rworking/deepseatools/indata/20241219-1_DatasetID_Key_DSCRTP.xlsx")
key <- read.xlsx("C:/rworking/deepseatools/indata/20250714-0_DatasetID_Key_DSCRTP.xlsx")

##### add new DatasetIDs to DatasetID key (watch this one closely) #####
## setdiff(filt$DatasetID, old_key$DatasetID)
changed <- setdiff(key$DatasetID, filt$DatasetID)
added <- setdiff(filt$DatasetID, key$DatasetID)

added_df <- data.frame(
  DatasetID = added,
  class = NA,
  title = NA,
  method_link = NA,
  method_text = NA,
  single_citation = NA,
  abstract = NA,
  Comments = NA,
  n = NA,
  stringsAsFactors = FALSE
)

## combine the old and new data
key1 <- rbind(key, added_df)

## cleanup
rm(added_df)

##### manual: update the class field in key for each new dataset 'added' #####
key2 <- key1 %>%
  mutate(
    class = case_when(
      DatasetID == "Choy_et_al_2020" ~ 'Literature',
      DatasetID == "Lehnert_and_Stone_2016" ~ 'Literature',
      DatasetID == "Watling_2015" ~ 'Literature',
      DatasetID == "Shen_2019" ~ 'Literature',
      DatasetID == "Baco_et_al_2023" ~ 'Literature',
      DatasetID == "Shen_et_al_2022" ~ 'Literature',
      DatasetID == "Watling_et_al_2022" ~ 'Literature',
      DatasetID == "OET_NA168" ~ 'Cruise',
      DatasetID == "OET_NA156" ~ 'Cruise',
      TRUE ~ class
    )
  )

##### loop to create title and abstract and method_link, and citation #####
for (dataset in added) {
  # Filter once
  subset_filt <- filt %>% filter(DatasetID == dataset)

  ## Create new title
  new_title <- subset_filt %>%
    summarise(
      title_text = paste(
        unique(DataProvider), ' | ',
        unique(Vessel), ' | ',
        unique(SurveyID), ' | ',
        unique(SamplingEquipment), ' | ',
        'Observation Dates: ',
        min(ObservationDate), ' to ',
        max(ObservationDate),
        sep = ""
      )
    ) %>%
    pull(title_text)

  key2 <- key2 %>%
    mutate(title = ifelse(DatasetID == dataset, new_title, title))

  ## Create new method_link
  new_web <- subset_filt %>%
    summarise(
      weblinks = paste(unique(WebSite), collapse = ' | ')
    ) %>%
    pull(weblinks)

  key2 <- key2 %>%
    mutate(method_link = ifelse(DatasetID == dataset, new_web, method_link))

  ## Create new abstract
  new_abstract <- subset_filt %>%
    summarise(
      abstract_text = paste(
        "NOTE: This abstract is autogenerated. NA's indicate null data within the underlying database.",
        " This biological occurence dataset was provided by ",
        paste(unique(DataProvider), collapse = '; '),
        " to NOAA's Deep-sea Coral Research and Technology Program. ",
        "Observations were from the vessel(s), ",
        paste(unique(Vessel), collapse = '; '), ",",
        " using the platform(s): ",
        paste(unique(VehicleName), collapse = '; '), ".",
        " Observation dates range from ",
        min(ObservationDate), " to ", max(ObservationDate), ".",
        " Marine Ecoregions of the World (MEOW) explored include: ",
        paste(unique(gisMEOW), collapse = '; '), ".",
        " Localities explored include: ",
        paste(unique(Locality), collapse = '; '), ".",
        " Changes to the originally submitted dataset may have been made to conform to the standards of NOAA's National Database for Deep-sea Corals and Sponges. ",
        "Please reach out to: ",
        paste(unique(DataContact), collapse = '; '),
        " for specific questions about this dataset.",
        " Link(s) for more information: ",
        paste(unique(WebSite), collapse = '; ')
      )
    ) %>%
    pull(abstract_text)

  key2 <- key2 %>%
    mutate(abstract = ifelse(DatasetID == dataset, new_abstract, abstract))

  ## Create new single_citation
  new_citation <- subset_filt %>%
    summarise(
      citation_text = paste(unique(Citation), collapse = ' | ')
    ) %>%
    pull(citation_text)

  key2 <- key2 %>%
    mutate(single_citation = ifelse(DatasetID == dataset, new_citation, single_citation))
}

##### clean up titles in key #####
key2$title  <- key2$title %>% str_split(" \\| ") %>%                             # Split by " | "
  lapply(function(x) x[x != "NA"]) %>%               # Remove 'NA'
  sapply(function(x) paste(x, collapse = " | "))     # Paste back together

key2$title

##### clean up method_link in key#####
key2$method_link  <- key2$method_link %>% str_split(" \\| ") %>%                             # Split by " | "
  lapply(function(x) x[x != "NA"]) %>%               # Remove 'NA'
  sapply(function(x) paste(x, collapse = " | "))     # Paste back together

##### set method_text in key #####
key2 <- key2 %>%
  mutate(
    method_text = case_when(
      DatasetID %in% added ~ "See link for methods.",
      TRUE ~ method_text  # Keep existing value otherwise
    )
  )
##### write the citation information into the database #####

filt$CitationMaker <- paste(filt$DataProvider,'. ',
                            filt$ObservationYear,
                            ' to ',
                            filt$ObservationYear,
                            '. ',
                            'Coral or sponge occurrence observations submitted to the NOAA National Database for Deep Sea Corals (www.deepseacoraldata.noaa.gov)', '. ',
                            'DSCRTP Dataset ID: ', filt$DatasetID, '. ',
                            'DSCRTP Accession ID: ',filt$AccessionID, '. ',
                            'Record type: ', filt$RecordType, '. ',
                            'Vessel(s): ', filt$Vessel,'. ',
                            'Sampling vehicle: ', filt$VehicleName,'. ',
                            'Survey ID: ', filt$SurveyID,'. ',
                            'Principle investigator: ', filt$PI,'. ',
                            'Data contact: ', filt$DataContact,'. ',
                            'Reporter: ', filt$Reporter,'. ',
                            'Repository: ', filt$Repository,'. ',
                            'Web site [last accessed on YYYY-MM-DD]: ', filt$WebSite,'.',
                            sep = '')

##### checking: looking at the Citation #####

# OET_NA138
# Baco et al. 2023
# Bayer_1958
# HBOM
# SAM
# SAMC
# NTM
# JAMSTEC
# NSMT
# Shen et al. 2022
# BAMZ
# Watling et al. 2022
# Xavier_et_al_2015
# Gastineau_et_al_2023
# Macrina_et_al_2024
# NMCIC

# x <- "MACN"
#
# y <- filt %>% filter(DatasetID == x) %>%
#   group_by(WebSite,
#            DataProvider,
#            DatasetID,
#            ObservationYear,
#            CitationMaker) %>%
#   summarize(n=n()) %>%  View()
#
# filt %>% filter(DatasetID == x) %>%
#   pull(CitationMaker) %>%
#   unique()

##### updating DatasetID key with new 'n' #####
key <- key2
## build a frequency table by DatasetID from new key file
x <- filt %>% group_by(DatasetID) %>% summarize(n=n())

# strip 'n' from existing key
names(key)
y <- key[,1:8]

x$DatasetID <- as.character(x$DatasetID)
y$DatasetID <- as.character(y$DatasetID)

## check
# names(y)
# View(y)

## merge new numbers to create old key + new counts
z <- left_join(y,x)
key <- z

##### set 'filt' to d. You can filter at this step if needed #####
d <- filt # %>% filter(DatasetID == 'OET_NA154')

##### ***** important!! merge database with key ***** #####
d <- merge(d, key, all.x = TRUE)

##### checking #####
# d %>% pull(DatasetID) %>% table(useNA = 'always')

# x <- d %>% filter(DatasetID == "Carranza_etal_2012")
# write.csv(test, "c:/rworking/deepseatools/indata/carranza.csv")
# test2 <- read_utf8("c:/rworking/deepseatools/indata/carranza.csv")

# d %>% filter(CatalogNumber == '618051') %>% pull(Citation)


# table(d$class, useNA = 'always')
#
# x <- d %>%
#   group_by(class) %>%
#   summarize(DatasetsbyClass = length(unique(DatasetID)),
#     n = n())
# View(x)

# setdiff(d$DatasetID, key$DatasetID)
# setdiff(key$DatasetID, d$DatasetID)
# #
# x <- d #%>%
#   # filter(
#   #   is.na(class) == T,
#   #   #DataProvider == "Temple University",
#   #   #class == "Literature"
#   #   )
#
# table(factor(x$class), useNA = 'always')
#
# library(stringr)
# test <- stringr::str_conv(d, "UTF-8")

##### *** run the reports *** #####
##### assign which datasets cross the 180 line #####
yo <- d %>%
  filter(as.numeric(Longitude) > 0) %>%
  pull(DatasetID) %>%
  unique()

yo2 <- d %>%
  filter(as.numeric(Longitude) < 0) %>%
  pull(DatasetID) %>%
  unique()

one_eighty <- intersect(yo, yo2)
not_one_eighty <- setdiff(d$DatasetID, one_eighty)

##### _create the folders for each type of report #####
dir.create('C:/rworking/deepseatools/reports/datasetid/cruise')
dir.create('C:/rworking/deepseatools/reports/datasetid/literature')
dir.create('C:/rworking/deepseatools/reports/datasetid/program')
dir.create('C:/rworking/deepseatools/reports/datasetid/repository')

##### _cruise #####
#cruise subset
yo <- d %>%
  filter(
    class == 'Cruise',
    DatasetID %in% not_one_eighty
  )

# length(unique(yo$DatasetID))
# run RMD
library("rmarkdown")
for (id in unique(yo$DatasetID)){
  sub <- yo[yo$DatasetID == id,]
  render("C:/rworking/deepseatools/code/rmd_datasetid_cruise_no_leaflet.rmd" ,
         output_file =  paste(id,".html", sep=''),
         output_dir = 'C:/rworking/deepseatools/reports/datasetid/cruise')
}

yo <- d %>%
  filter(
    class == 'Cruise',
    DatasetID %in% one_eighty
  )

# length(unique(yo$DatasetID)
# run RMD

library("rmarkdown")
for (id in unique(yo$DatasetID)){
  sub <- yo[yo$DatasetID == id,]
  render("C:/rworking/deepseatools/code/rmd_datasetid_cruise_no_leaflet_one_eighty.rmd" ,
         output_file =  paste(id,".html", sep=''),
         output_dir = 'C:/rworking/deepseatools/reports/datasetid/cruise')
}

##### _literature ######
yo <- d %>%
  filter(
    class == 'Literature',
    DatasetID %in% not_one_eighty
  )

library("rmarkdown")
for (id in unique(yo$DatasetID)){
  sub <- yo[yo$DatasetID == id,]
  render("C:/rworking/deepseatools/code/rmd_datasetid_literature_no_leaflet.rmd" ,
         output_file =  paste(id,".html", sep=''),
         output_dir = 'C:/rworking/deepseatools/reports/datasetid/literature')
}

yo <- d %>%
  filter(
    class == 'Literature',
    DatasetID %in% one_eighty
  )

library("rmarkdown")
for (id in unique(yo$DatasetID)){
  sub <- yo[yo$DatasetID == id,]
  render("C:/rworking/deepseatools/code/rmd_datasetid_literature_no_leaflet_one_eighty.rmd" ,
         output_file =  paste(id,".html", sep=''),
         output_dir = 'C:/rworking/deepseatools/reports/datasetid/literature')
}

##### _program #####
yo <- d %>%
  filter(
    class == 'Program',
    DatasetID %in% not_one_eighty
  )

library("rmarkdown")
for (id in unique(yo$DatasetID)){
  sub <- yo[yo$DatasetID == id,]
  render("C:/rworking/deepseatools/code/rmd_datasetid_program_no_leaflet.rmd" ,
         output_file =  paste(id,".html", sep=''),
         output_dir = 'C:/rworking/deepseatools/reports/datasetid/program')
}

yo <- d %>%
  filter(
    class == 'Program',
    DatasetID %in% one_eighty
  )

library("rmarkdown")
for (id in unique(yo$DatasetID)){
  sub <- yo[yo$DatasetID == id,]
  render("C:/rworking/deepseatools/code/rmd_datasetid_program_no_leaflet_one_eighty.rmd" ,
         output_file =  paste(id,".html", sep=''),
         output_dir = 'C:/rworking/deepseatools/reports/datasetid/program')
}

##### _repository #####
yo <- d %>%
  filter(
    class == 'Repository',
    DatasetID %in% not_one_eighty
  )

library("rmarkdown")
for (id in unique(yo$DatasetID)){
  sub <- yo[yo$DatasetID == id,]
  render("C:/rworking/deepseatools/code/rmd_datasetid_repository_no_leaflet.rmd" ,
         output_file =  paste(id,".html", sep=''),
         output_dir = 'C:/rworking/deepseatools/reports/datasetid/repository')
}

yo <- d %>%
  filter(
    class == 'Repository',
    DatasetID %in% one_eighty
  )

library("rmarkdown")
for (id in unique(yo$DatasetID)){
  sub <- yo[yo$DatasetID == id,]
  render("C:/rworking/deepseatools/code/rmd_datasetid_repository_no_leaflet_one_eighty.rmd" ,
         output_file =  paste(id,".html", sep=''),
         output_dir = 'C:/rworking/deepseatools/reports/datasetid/repository')
}

##### _repository:MBARI #####
yo <- d %>%
  filter(
    DatasetID == 'MBARI'
  )

library("rmarkdown")
for (id in unique(yo$DatasetID)){
  sub <- yo[yo$DatasetID == id,]
  render("C:/rworking/deepseatools/code/rmd_datasetid_repository_MBARI_no_leaflet.rmd" ,
         output_file =  paste(id,".html", sep=''),
         output_dir = 'C:/rworking/deepseatools/reports/datasetid/repository')
}

##### check #####
d %>% filter(class == 'Cruise') %>% pull(DatasetID) %>% unique() %>% length()
d %>% filter(class == 'Literature') %>% pull(DatasetID) %>% unique() %>% length()
d %>% filter(class == 'Program') %>% pull(DatasetID) %>% unique() %>% length()
d %>% filter(class == 'Repository') %>% pull(DatasetID) %>% unique() %>% length()

cruise <- list.files('C:/rworking/deepseatools/reports/datasetid/cruise/')
literature <- list.files('C:/rworking/deepseatools/reports/datasetid/literature/')
program <- list.files('C:/rworking/deepseatools/reports/datasetid/program/')
repository <- list.files('C:/rworking/deepseatools/reports/datasetid/repository/')

length(cruise) +
length(literature) +
length(program) +
length(repository)

biglist <- c(cruise, literature, program, repository)
biglist <- gsub(pattern = "\\.html$", "", biglist)

setdiff(biglist, d$DatasetID)
setdiff(d$DatasetID, biglist)
setdiff(key$DatasetID, d$DatasetID)
setdiff(d$DatasetID,key$DatasetID)
length(unique(d$DatasetID))
length(biglist)
length(key$DatasetID)
length(unique(filt$DatasetID))

##### write out new DatasetID key #####
write.xlsx(key, "C:/rworking/deepseatools/indata/20250714-0_DatasetID_Key_DSCRTP.xlsx",
           overwrite = TRUE)
