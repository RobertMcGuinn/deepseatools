##### Header #####
## author: Robert P. McGuinn, robert.mcguinn@noaa.gov, rpm@alumni.duke.edu
## startdate:20260123
## purpose: update the DatasetID Key with information from the new datasets

##### packages #####
library(tidyverse)
library(sf)
library(remotes)
library(terra)
library(ggplot2)
library(rnaturalearth)
library(rnaturalearthdata)
library(googlesheets4)
library(robis)
library(googledrive)
library(openxlsx)

##### authorizations #####
gs4_auth(cache = ".secrets", email = "robert.mcguinn@noaa.gov")
drive_auth(cache = ".secrets", email = "robert.mcguinn@noaa.gov")

##### load current database from disk #####
# source("c:/rworking/deepseatools/code/dst_tool_load_current_ndb.R")

##### parameters: manual input #####
## get the current database version
version <- unique(filt$DatabaseVersion)
version <- as.character(version)

## indicate filename of this file without the extension
filename <- 'dst_tool_update_datasetid_key'

## indicate the Google Drive ID of the current DatasetID Key (points to a Google Sheet)
sheetid <- '1J3aYaox0bmyR_lI03_s7pmnKctdOSNXi-SQWmtzzcUo'

## get the title of the current DatasetID Key
ss <- gs4_get(sheetid)
title <- ss$name

## indicate the version number of the current DatasetID Key
key_version <- sub("_.*", "", ss$name)

## indicate the new key version (follows current database version)
key_version_new <- unique(filt$DatabaseVersion)

##### linkage to github repo #####
github_path <- 'https://github.com/RobertMcGuinn/deepseatools/blob/master/code/'
github_link <- paste(github_path, filename, '.R', sep = '')
# browseURL(github_link)

##### load current DatasetID key from local path -- OR -- #####
# optional: bring in old key for testing
# old_key <- read.xlsx("C:/rworking/deepseatools/indata/20241219-1_DatasetID_Key_DSCRTP.xlsx")
# key <- read.xlsx(paste("C:/rworking/deepseatools/indata/",
#                        key_version,
#                        "DatasetID_Key_DSCRTP.xlsx",
#                        sep = ''))

##### load current DatasetID key from Google Drive (preferred) -- OR --#####
key <- read_sheet(sheetid)

## save a copy of original key for testing.
og_key <- key

##### add new DatasetIDs to DatasetID key (watch this one closely) #####
## setdiff(filt$DatasetID, old_key$DatasetID)
changed <- setdiff(key$DatasetID, filt$DatasetID)
added <- setdiff(filt$DatasetID, key$DatasetID)

added_df <- data.frame(
  DatasetID = added,
  class = NA,
  title = NA,
  method_link = NA,
  method_text = NA,
  single_citation = NA,
  abstract = NA,
  Comments = NA,
  n = NA,
  stringsAsFactors = FALSE
)

## combine the old and new data
key1 <- rbind(key, added_df)

## cleanup
rm(added_df)

##### manual: update the class field in key for each new dataset 'added' #####
key2 <- key1 %>%
  mutate(
    class = case_when(
      DatasetID == "OET_NA165" ~ 'Cruise',
      TRUE ~ class
    )
  )

##### loop to create title and abstract and method_link, and citation #####
for (dataset in added) {
  ## Filter once
  subset_filt <- filt %>% filter(DatasetID == dataset)

  ## 1. Create new title
  new_title <- subset_filt %>%
    summarise(
      title_text = paste(
        unique(DataProvider), ' | ',
        unique(Vessel), ' | ',
        unique(SurveyID), ' | ',
        unique(SamplingEquipment), ' | ',
        'Observation Dates: ',
        min(ObservationDate), ' to ',
        max(ObservationDate),
        sep = ""
      )
    ) %>%
    pull(title_text)

  key2 <- key2 %>%
    mutate(title = ifelse(DatasetID == dataset, new_title, title))

  ## 2. Create new method_link
  new_web <- subset_filt %>%
    summarise(
      weblinks = paste(unique(WebSite), collapse = ' | ')
    ) %>%
    pull(weblinks)

  key2 <- key2 %>%
    mutate(method_link = ifelse(DatasetID == dataset, new_web, method_link))

  ## Create new abstract
  base_abstract <- subset_filt %>%
    summarise(
      abstract_text = paste(
        "NOTE: This abstract is autogenerated. NA's indicate null data within the underlying database.",
        " This biological occurence dataset was provided by ",
        paste(unique(DataProvider), collapse = '; '),
        " to NOAA's Deep-sea Coral Research and Technology Program. ",
        "Observations were from the vessel(s), ",
        paste(unique(Vessel), collapse = '; '), ",",
        " using the platform(s): ",
        paste(unique(VehicleName), collapse = '; '), ".",
        " Observation dates range from ",
        min(ObservationDate), " to ", max(ObservationDate), ".",
        " Marine Ecoregions of the World (MEOW) explored include: ",
        paste(unique(gisMEOW), collapse = '; '), ".",
        " Localities explored include: ",
        paste(unique(Locality), collapse = '; '), ".",
        " Changes to the originally submitted dataset may have been made to conform to the standards of NOAA's National Database for Deep-sea Corals and Sponges. ",
        "Please reach out to: ",
        paste(unique(DataContact), collapse = '; '),
        " for specific questions about this dataset.",
        " Link(s) for more information: ",
        paste(unique(WebSite), collapse = '; ')
      )
    ) %>%
    pull(abstract_text)

  # Check for specific DatasetID to append custom verbiage
  if (dataset == "OET_NA165") {
    custom_attribution <- " Data attribution statement: This research used data collected by E/V Nautilus expedition NA165, which was supported by NOAA Ocean Exploration, NOAA Uncrewed Systems Operation Center, and Bureau of Ocean Energy Management via the Ocean Exploration Cooperative Institute NA19OAR4320072, and executed under permit NMSAS-2024-003 authorized by the NOAA Office of National Marine Sanctuaries, and permit 2024-003 authorized by the Department of Marine and Wildlife Resources of American Samoa. Special thanks to the captain and crew of E/V Nautilus, the Nautilus Corps of Exploration, the Ocean Exploration Trust, and all that supported the expedition from shore."
    new_abstract <- paste0(base_abstract, custom_attribution)
  } else {
    new_abstract <- base_abstract
  }

  # Update the key2 dataframe
  key2 <- key2 %>%
    mutate(abstract = ifelse(DatasetID == dataset, new_abstract, abstract))

  ## ... [Keep citation code as is] ...
}
##### clean up titles in key #####
key2$title  <- key2$title %>% str_split(" \\| ") %>%                             # Split by " | "
  lapply(function(x) x[x != "NA"]) %>%               # Remove 'NA'
  sapply(function(x) paste(x, collapse = " | "))     # Paste back together

##### clean up method_link in key#####
key2$method_link  <- key2$method_link %>% str_split(" \\| ") %>%                             # Split by " | "
  lapply(function(x) x[x != "NA"]) %>%               # Remove 'NA'
  sapply(function(x) paste(x, collapse = " | "))     # Paste back together

##### set method_text in key #####
key2 <- key2 %>%
  mutate(
    method_text = case_when(
      DatasetID %in% added ~ "See link for methods.",
      TRUE ~ method_text  # Keep existing value otherwise
    )
  )











##### updating DatasetID key with new 'n' #####
key <- key2

## build a frequency table by DatasetID from new key file
x <- filt %>% group_by(DatasetID) %>% summarize(n=n())

# strip 'n' from existing key
y <- key[,1:8]

x$DatasetID <- as.character(x$DatasetID)
y$DatasetID <- as.character(y$DatasetID)

## check
# names(y)
# View(y)

## merge new numbers to create old key + new counts
z <- left_join(y,x)
key <- z

##### write out new DatasetID key to a local folder -- OR -- #####
write.xlsx(key,
           paste("C:/rworking/deepseatools/indata/",
                 key_version_new,
                 "_DatasetID_Key_DSCRTP.xlsx",
                 sep=''),
           overwrite = TRUE)

##### write out new DatasetID key to Google Drive #####

## 1. Set the name for the new Google Sheet
new_sheet_name <- paste0(key_version_new, "_DatasetID_Key_DSCRTP")

## 2. Your specific Folder ID
target_folder_id <- "1e851ZIEpDgYNmnnYwHQQZ9RyuNyz1aWf"

## 3. Create the sheet (This creates it in 'My Drive' initially)
new_ss_metadata <- gs4_create(
  name = new_sheet_name,
  sheets = list(DatasetID_Key = key) # Naming the tab 'DatasetID_Key'
)

## 4. Move it into the target folder
drive_mv(
  file = as_id(new_ss_metadata),
  path = as_id(target_folder_id)
)

message("File '", new_sheet_name, "' has been created and moved to the specified folder.")

##### check #####
key %>% filter(DatasetID == "OET_NA165") %>% group_by(DatasetID, title, method_link, method_text) %>%
  summarize(s=n()) %>% View()



